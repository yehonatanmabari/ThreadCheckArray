{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMu3RtEKDoO9+q/xGT4UzM0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yehonatanmabari/ThreadCheckArray/blob/master/Untitled21.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys, subprocess, pkgutil\n",
        "from google.colab import runtime\n",
        "\n",
        "# Clean extras\n",
        "try:\n",
        "    subprocess.run([sys.executable, \"-m\", \"pip\", \"uninstall\", \"-y\", \"google-genai\", \"google-adk\", \"dataproc-spark-connect\", \"yfinance\", \"bigframes\", \"datasets\", \"gcsfs\"], check=True, capture_output=True)\n",
        "    print(\"ğŸ§¹ Cleaned extras (if existed).\")\n",
        "except subprocess.CalledProcessError as e:\n",
        "    print(f\"Error cleaning extras: {e.stderr.decode()}\")\n",
        "\n",
        "# Install base packages\n",
        "subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"--no-cache-dir\", \"--force-reinstall\", \"numpy==2.0.2\", \"pandas==2.2.2\", \"requests==2.32.4\", \"gradio==4.44.1\", \"pypdf==4.3.1\", \"jedi>=0.18,<0.20\"], check=True, capture_output=True)\n",
        "print(\"âœ”ï¸ Base installed. Run the next cell to restart runtime.\")\n",
        "\n",
        "# Restart runtime (This needs to be a separate step as it cannot be done within the same script)\n",
        "# print(\"ğŸ” Restarting runtimeâ€¦\")\n",
        "# runtime.unassign()\n",
        "\n",
        "# Install additional packages\n",
        "subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"plotly==5.24.1\", \"sentence-transformers==2.7.0\", \"openai>=1.44.0\"], check=True, capture_output=True)\n",
        "print(\"âœ”ï¸ Extra deps installed\")\n",
        "\n",
        "# Ensure pypdf or PyPDF2 is installed\n",
        "def ensure_pdf_reader():\n",
        "    try:\n",
        "        from pypdf import PdfReader  # noqa\n",
        "        return \"pypdf\"\n",
        "    except ModuleNotFoundError:\n",
        "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"pypdf==4.3.1\"])\n",
        "        try:\n",
        "            from pypdf import PdfReader  # noqa\n",
        "            return \"pypdf\"\n",
        "        except ModuleNotFoundError:\n",
        "            subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"PyPDF2==3.0.1\"])\n",
        "            from PyPDF2 import PdfReader # type: ignore # noqa\n",
        "            globals()[\"PdfReader\"] = PdfReader\n",
        "            return \"PyPDF2\"\n",
        "\n",
        "provider = ensure_pdf_reader()\n",
        "if provider:\n",
        "    print(\"ğŸ“¦ PdfReader provider:\", provider)\n",
        "else:\n",
        "    print(\"âš ï¸ Could not import PdfReader. Please install pypdf or PyPDF2.\")\n",
        "\n",
        "# The code from cell f3mWXUmYD5Oz is included here\n",
        "subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"--no-cache-dir\", \"--force-reinstall\", \"google-genai>=1.0.0,<2.0.0\", \"websockets==14.1\", \"rich==13.9.4\"], check=True, capture_output=True)\n",
        "print(\"âœ”ï¸ Pinned google-genai + websockets 14.1\")\n",
        "\n",
        "\n",
        "import os, re, sys, json, requests, subprocess, importlib\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from io import BytesIO\n",
        "from functools import lru_cache\n",
        "from typing import List, Dict, Any, Tuple\n",
        "\n",
        "import gradio as gr\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from pypdf import PdfReader\n",
        "\n",
        "PK_URL1 = \"https://docs.google.com/spreadsheets/d/17oWJqasboi06fvb37NNsXNRd4Htk-91O0JhPy_cDx_w/export?format=csv&gid=41248493\"\n",
        "PK_URL2 = \"https://docs.google.com/spreadsheets/d/1tNjPmosEbpikgnK7wnqq8PF1Q_MZc39_StW4D-P2KsM/export?format=csv&gid=887161397\"\n",
        "\n",
        "PK_TURB  = \"avg_turbidity ntu\"\n",
        "PK_CY1   = \"cyanophyta_chroococales_2-microcystis_flos-aquae\"\n",
        "PK_CY2   = \"cyanophyta_hormogonales_2-cylindrospermopsis_raciborskyi\"\n",
        "PK_NO3   = \"avg_nitrate mg/L\"\n",
        "PK_NO2   = \"avg_nitrite mg/L\"\n",
        "PK_CL    = \"avg_cl mg/L\"\n",
        "PK_PH    = \"avg_ph \"  # ×™×© ×¨×•×•×— ×‘×¡×•×£ ×‘×›×•×ª×¨×ª ×‘×’×™×œ×™×•×Ÿ ×”××§×•×¨×™\n",
        "\n",
        "PK_WINDOW_MONTHS = 1\n",
        "PK_TOP_K = 5\n",
        "\n",
        "def _pk_to_num(s): return pd.to_numeric(s, errors=\"coerce\")\n",
        "def _pk_pct_rank(series): return series.rank(pct=True, na_option=\"keep\")\n",
        "\n",
        "def _pk_wqi(df: pd.DataFrame) -> pd.Series:\n",
        "    need = {PK_TURB: \"worse_high\", PK_NO3: \"worse_high\", PK_NO2: \"worse_high\",\n",
        "            PK_CL: \"worse_high\", PK_PH: \"ph\"}\n",
        "    available = {c:k for c,k in need.items() if c in df.columns}\n",
        "    subs = []\n",
        "    for col, kind in available.items():\n",
        "        if kind == \"worse_high\":\n",
        "            subs.append(1.0 - _pk_pct_rank(_pk_to_num(df[col])))\n",
        "        elif kind == \"ph\":\n",
        "            target = 8.2\n",
        "            penalty = (_pk_to_num(df[col]) - target).abs()\n",
        "            subs.append(1.0 - _pk_pct_rank(penalty))\n",
        "    if not subs:\n",
        "        return pd.Series([pd.NA]*len(df), index=df.index, name=\"WQI\")\n",
        "    wqi = pd.concat(subs, axis=1).mean(axis=1, skipna=True) * 100.0\n",
        "    return wqi.clip(0, 100).rename(\"WQI\")\n",
        "\n",
        "@lru_cache(maxsize=1)\n",
        "def pk_load_merged():\n",
        "    df1 = pd.read_csv(PK_URL1)\n",
        "    df2 = pd.read_csv(PK_URL2)\n",
        "    df1[\"date\"] = pd.to_datetime(df1[\"date\"], errors=\"coerce\", utc=True).dt.tz_convert(None)\n",
        "    df2[\"date\"] = pd.to_datetime(df2[\"date\"], errors=\"coerce\", utc=True).dt.tz_convert(None)\n",
        "    merged = (pd.merge(df1, df2, on=\"date\", how=\"outer\")\n",
        "                .sort_values(\"date\").reset_index(drop=True))\n",
        "    merged[PK_TURB] = _pk_to_num(merged.get(PK_TURB))\n",
        "    merged[\"plankton amount\"] = _pk_to_num(merged.get(PK_CY1)).add(\n",
        "        _pk_to_num(merged.get(PK_CY2)), fill_value=0\n",
        "    )\n",
        "    merged[\"WQI\"] = _pk_wqi(merged)\n",
        "    return merged\n",
        "\n",
        "def pk_top5_dates(df: pd.DataFrame):\n",
        "    s = df[[\"date\", PK_TURB]].dropna(subset=[PK_TURB])\n",
        "    return s.nlargest(PK_TOP_K, PK_TURB)[\"date\"].dropna().tolist()\n",
        "\n",
        "def _pk_window(df: pd.DataFrame, center_ts, months: int):\n",
        "    start = center_ts - pd.DateOffset(months=months)\n",
        "    end   = center_ts + pd.DateOffset(months=months)\n",
        "    win = df[(df[\"date\"] >= start) & (df[\"date\"] <= end)].copy()\n",
        "    return win.sort_values(\"date\")\n",
        "\n",
        "def pk_build_plots_for_rank(rank: int):\n",
        "    try:\n",
        "        df = pk_load_merged()\n",
        "        peaks = pk_top5_dates(df)\n",
        "        if not peaks:\n",
        "            raise ValueError(\"No valid turbidity values found.\")\n",
        "        rank = max(1, min(rank, len(peaks)))\n",
        "        peak_date = pd.Timestamp(peaks[rank-1])\n",
        "        win = _pk_window(df, peak_date, PK_WINDOW_MONTHS)\n",
        "\n",
        "        # Fig 1: Turbidity vs Plankton\n",
        "        fig1 = make_subplots(specs=[[{\"secondary_y\": True}]])\n",
        "        fig1.add_trace(go.Scatter(x=win[\"date\"], y=win[PK_TURB],\n",
        "                                  mode=\"lines\", name=PK_TURB, connectgaps=True),\n",
        "                       secondary_y=False)\n",
        "        fig1.add_trace(go.Scatter(x=win[\"date\"], y=win[\"plankton amount\"],\n",
        "                                  mode=\"lines\", name=\"plankton amount\", connectgaps=True),\n",
        "                       secondary_y=True)\n",
        "        fig1.update_layout(\n",
        "            title=f\"Â±{PK_WINDOW_MONTHS} month around peak #{rank} â€” {peak_date.date()} (connectgaps=True)\",\n",
        "            legend=dict(orientation=\"h\", yanchor=\"bottom\", y=1.02, xanchor=\"left\", x=0),\n",
        "            margin=dict(l=40, r=40, t=70, b=40), height=440\n",
        "        )\n",
        "        fig1.update_xaxes(title_text=\"Date\")\n",
        "        fig1.update_yaxes(title_text=PK_TURB, secondary_y=False)\n",
        "        fig1.update_yaxes(title_text=\"plankton amount\", secondary_y=True)\n",
        "\n",
        "        # Fig 2: WQI vs Plankton\n",
        "        fig2 = make_subplots(specs=[[{\"secondary_y\": True}]])\n",
        "        fig2.add_trace(go.Scatter(x=win[\"date\"], y=win[\"WQI\"],\n",
        "                                  mode=\"lines\", name=\"Water Quality Index (0â€“100)\", connectgaps=True),\n",
        "                       secondary_y=False)\n",
        "        fig2.add_trace(go.Scatter(x=win[\"date\"], y=win[\"plankton amount\"],\n",
        "                                  mode=\"lines\", name=\"plankton amount\", connectgaps=True),\n",
        "                       secondary_y=True)\n",
        "        fig2.update_layout(\n",
        "            title=\"Water Quality vs Plankton â€” same window (connectgaps=True)\",\n",
        "            legend=dict(orientation=\"h\", yanchor=\"bottom\", y=1.02, xanchor=\"left\", x=0),\n",
        "            margin=dict(l=40, r=40, t=60, b=40), height=440\n",
        "        )\n",
        "        fig2.update_xaxes(title_text=\"Date\")\n",
        "        fig2.update_yaxes(title_text=\"Water Quality Index (0â€“100)\", secondary_y=False, range=[0, 100])\n",
        "        fig2.update_yaxes(title_text=\"plankton amount\", secondary_y=True)\n",
        "\n",
        "        return fig1, fig2\n",
        "    except Exception as e:\n",
        "        err = go.Figure()\n",
        "        err.add_annotation(text=f\"Error: {e}\", xref=\"paper\", yref=\"paper\",\n",
        "                           x=0.01, y=0.9, showarrow=False, font=dict(size=14))\n",
        "        err.update_layout(height=220, margin=dict(l=20, r=20, t=40, b=20))\n",
        "        return err, err\n",
        "# ==== /Peaks ====\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# ============ OpenAI client (optional) ============\n",
        "\n",
        "from openai import OpenAI\n",
        "#enter code i cant publish my own tokken\n",
        "API_KEY = os.environ.get(\"OPENAI_API_KEY\") or\n",
        "USE_OPENAI = bool(API_KEY)\n",
        "openai_client = OpenAI(api_key=API_KEY) if USE_OPENAI else None\n",
        "GEN_MODEL = \"gpt-4o-mini\"\n",
        "\n",
        "def _test_openai():\n",
        "    if not USE_OPENAI:\n",
        "        print(\"â„¹ï¸ OPENAI_API_KEY ×œ× ×”×•×’×“×¨ â€” × ×¤×¢×™×œ fallback ×œ×œ× ××•×“×œ.\")\n",
        "        return\n",
        "    try:\n",
        "        _ = openai_client.chat.completions.create(\n",
        "            model=GEN_MODEL,\n",
        "            messages=[{\"role\":\"user\",\"content\":\"×‘×“×™×§×” ×§×¦×¨×”\"}],\n",
        "            max_tokens=5\n",
        "        )\n",
        "        print(\"âœ… OpenAI\")\n",
        "    except Exception as e:\n",
        "        print(\"âŒ OpenAI:\", e)\n",
        "        globals()[\"USE_OPENAI\"] = False\n",
        "_test_openai()\n",
        "\n",
        "# ============ PDF RAG building ============\n",
        "PDF_URL = \"https://www.ocean.org.il/wp-content/uploads/2025/03/T10-2024-%D7%A0%D7%99%D7%98%D7%95%D7%A8-%D7%95%D7%9E%D7%97%D7%A7%D7%A8%D7%99-%D7%9B%D7%A0%D7%A8%D7%AA-%D7%9C%D7%A9%D7%A0%D7%AA-2023.pdf\"\n",
        "SECTIONS = [\n",
        "    (\"×—×•××¨ ××•×¨×’× ×™ ×•××™-××•×¨×’× ×™ ××•××¡\", 57, 62),\n",
        "    (\"× ×™×˜×•×¨ ×¤×™×˜×•×¤×œ× ×§×˜×•×Ÿ\",          78, 84),\n",
        "    (\"× ×™×˜×•×¨ ×–×•××•×¤×œ× ×§×˜×•×Ÿ\",          89, 94),\n",
        "    (\"××¢×§×‘ ×¤×¨×™×—×•×ª ×¦×™×× ×•×‘×§×˜×¨×™×”\",    119, 122),\n",
        "    (\"×”×©×•×•××” ×¨×‘Ö¾×©× ×ª×™×ª\",            76, 80),\n",
        "]\n",
        "\n",
        "EMBED_MODEL   = \"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\"\n",
        "CHUNK_SIZE    = 900\n",
        "#Maximum number of characters in each text chunk.\n",
        "CHUNK_OVERLAP = 120\n",
        "#Number of overlapping characters between consecutive chunks.\n",
        "TOP_K         = 3\n",
        "#Number of most relevant chunks to retrieve for a query.\n",
        "MAX_CTX_CHARS = 1200\n",
        "#Maximum total characters of retrieved text passed to the language model.\n",
        "\n",
        "def clean_spaces(s: str) -> str:\n",
        "    return re.sub(r\"\\s+\", \" \", (s or \"\")).strip()\n",
        "\n",
        "def chunk_text(text: str, size=CHUNK_SIZE, overlap=CHUNK_OVERLAP) -> List[str]:\n",
        "    text = clean_spaces(text)\n",
        "    out, i, step = [], 0, max(size - overlap, 1)\n",
        "    while i < len(text):\n",
        "        out.append(text[i:i+size]); i += step\n",
        "    return out\n",
        "\n",
        "def download_pdf(url: str) -> PdfReader:\n",
        "    r = requests.get(url, timeout=60); r.raise_for_status()\n",
        "    return PdfReader(BytesIO(r.content))\n",
        "\n",
        "def extract_range(reader: PdfReader, start_1: int, end_1: int) -> str:\n",
        "    start, end = start_1 - 1, end_1 - 1\n",
        "    parts = []\n",
        "    for i in range(start, end + 1):\n",
        "        try:        t = reader.pages[i].extract_text() or \"\"\n",
        "        except Exception: t = \"\"\n",
        "        parts.append(t)\n",
        "    return clean_spaces(\"\\n\".join(parts))\n",
        "\n",
        "Doc = Dict[str, Any]  # {\"text\": str, \"meta\": {\"title\": str, \"url\": str, \"chunk_id\": int}}\n",
        "\n",
        "def build_docs(pdf_url: str, sections: List[Tuple[str,int,int]]) -> List[Doc]:\n",
        "    reader = download_pdf(pdf_url)\n",
        "    docs: List[Doc] = []\n",
        "    for title, p1, p2 in sections:\n",
        "        full_text = extract_range(reader, p1, p2)\n",
        "        if not full_text.strip():\n",
        "            continue\n",
        "        for ci, ch in enumerate(chunk_text(full_text)):\n",
        "            docs.append({\"text\": ch, \"meta\": {\"title\": f\"{title} (×¢××³ {p1}-{p2})\", \"url\": pdf_url, \"chunk_id\": ci}})\n",
        "    return docs\n",
        "\n",
        "class SimpleVectorStore:\n",
        "    def __init__(self, embed_model=EMBED_MODEL):\n",
        "        self.embedder = SentenceTransformer(embed_model)\n",
        "        self.docs: List[Doc] = []\n",
        "        self.vecs: List[np.ndarray] = []\n",
        "\n",
        "    def add(self, docs: List[Doc]):\n",
        "        if not docs: return\n",
        "        embs = self.embedder.encode([d[\"text\"] for d in docs], normalize_embeddings=True)\n",
        "        self.docs.extend(docs)\n",
        "        self.vecs.extend(embs)\n",
        "\n",
        "    def search(self, query: str, k=TOP_K) -> List[Tuple[Doc, float]]:\n",
        "        if not self.vecs: return []\n",
        "        q = self.embedder.encode([query], normalize_embeddings=True)[0]\n",
        "        sims = np.dot(np.stack(self.vecs), q)\n",
        "        idx = np.argsort(sims)[::-1][:k]\n",
        "        return [(self.docs[i], float(sims[i])) for i in idx]\n",
        "\n",
        "DOCS = build_docs(PDF_URL, SECTIONS)\n",
        "STORE = SimpleVectorStore(EMBED_MODEL)\n",
        "STORE.add(DOCS)\n",
        "\n",
        "def rag_search(query: str, k: int = TOP_K):\n",
        "    hits = STORE.search(query, k=k)\n",
        "    out = []\n",
        "    for doc, score in hits:\n",
        "        snippet = (doc[\"text\"][:160] + \"â€¦\") if len(doc[\"text\"]) > 160 else doc[\"text\"]\n",
        "        out.append({\"title\": doc[\"meta\"][\"title\"], \"url\": doc[\"meta\"][\"url\"], \"score\": round(score,3), \"snippet\": snippet})\n",
        "    return out\n",
        "\n",
        "def _trim_hebrew(text: str, max_chars: int = 400, max_words: int = 80, max_sentences: int = 6) -> str:\n",
        "    parts = re.split(r'(?<=[\\.\\!\\?])\\s+|\\n+', (text or \"\").strip())\n",
        "    parts = [p.strip() for p in parts if p.strip()]\n",
        "    short = \" \".join(parts[:max_sentences])\n",
        "    words = short.split()\n",
        "    if len(words) > max_words:\n",
        "        short = \" \".join(words[:max_words])\n",
        "    if len(short) > max_chars:\n",
        "        short = short[:max_chars].rstrip()\n",
        "    if short and short[-1] not in \".!?â€¦\":\n",
        "        short += \"â€¦\"\n",
        "    return short\n",
        "\n",
        "SAFE_FALLBACK = \"×œ× × ×™×ª×Ÿ ×œ×”×¡×™×§ ××¦×‘ ××”××™×“×¢ ×”×§×™×™×.\"\n",
        "SAFE_PHRASE   = \"×œ× × ×™×ª×Ÿ ×œ×”×¡×™×§ ××¦×‘\"\n",
        "\n",
        "def _short_best_effort_from_hits(hits, max_chars=400):\n",
        "    if not hits:\n",
        "        return SAFE_FALLBACK\n",
        "    text = \" \".join(h[\"snippet\"] for h in hits[:3])\n",
        "    text = clean_spaces(text)\n",
        "    return _trim_hebrew(text, max_chars=max_chars, max_words=80, max_sentences=2)\n",
        "\n",
        "def rag_explain_bad(question: str, k: int = TOP_K, max_ctx_chars: int = MAX_CTX_CHARS,\n",
        "                    max_sentences: int = 8, max_words: int = 100, max_chars: int = 600) -> str:\n",
        "    hits = rag_search(question, k=k)\n",
        "    if not hits:\n",
        "        return SAFE_FALLBACK\n",
        "    ctx = \"\\n\\n\".join(f\"[{h['title']}] {h['snippet']}\" for h in hits)[:max_ctx_chars]\n",
        "    sys_msg = (\n",
        "        \"×¢× ×” ×‘×× ×’×œ×™×ª ×¤×©×•×˜×”, ×¢×“ ×©×™×©×” ××©×¤×˜×™× ×œ×›×œ ×”×™×•×ª×¨, ×œ××” ×”××¦×‘ ×˜×•×‘ ××• ×œ× ×˜×•×‘. \"\n",
        "        \"×”×ª×‘×¡×¡ ××š ×•×¨×§ ×¢×œ ×”×§×•× ×˜×§×¡×˜. ××œ ×ª×¦×˜×˜, ××œ ×ª×›×œ×•×œ ××§×•×¨×•×ª, ×›×•×ª×¨×•×ª ××• ×¨×©×™××•×ª. \"\n",
        "        \"×× ××™ ××¤×©×¨ ×œ×”×¡×™×§ â€” ×›×ª×•×‘ '×œ× × ×™×ª×Ÿ ×œ×”×¡×™×§ ××¦×‘'.\"\n",
        "        \"×× ××¤×©×¨ ×ª×Ÿ ×ª×—×–×™×ª ×¢×ª×™×“×™×ª.\"\n",
        "\n",
        "    )\n",
        "    ans = None\n",
        "    if USE_OPENAI and openai_client:\n",
        "        try:\n",
        "            resp = openai_client.chat.completions.create(\n",
        "                model=GEN_MODEL,\n",
        "                messages=[{\"role\":\"system\",\"content\":sys_msg},\n",
        "                          {\"role\":\"user\",\"content\":f\"×§×•× ×˜×§×¡×˜:\\n{ctx}\\n\\n×©××œ×”: {question}\"}],\n",
        "                temperature=0.0, max_tokens=180\n",
        "            )\n",
        "            ans = (resp.choices[0].message.content or \"\").strip()\n",
        "        except Exception:\n",
        "            ans = None\n",
        "    if not ans:\n",
        "        ans = \"×”××¦×‘ ××™× ×• ×˜×•×‘ ×¢×§×‘ ×—×•×¡×¨ ××™×–×•×Ÿ ××§×•×œ×•×’×™: ×“×•××™× × ×˜×™×•×ª ×©×œ ××™× ×™× ××¡×•×™××™× ×œ×¦×“ ×™×¨×™×“×” ×‘×©×¤×¢/×‘×™×•××¡×” ×”×›×•×œ×œ×ª.\"\n",
        "    return _trim_hebrew(ans, max_chars=max_chars, max_words=max_words, max_sentences=max_sentences)\n",
        "\n",
        "def rag_answer_tiny(question: str, k: int = 8, max_ctx_chars: int = 2400) -> str:\n",
        "    hits = rag_search(question, k=k)\n",
        "    if not hits:\n",
        "        return SAFE_FALLBACK\n",
        "    ctx = \"\\n\\n\".join(f\"[{h['title']}] {h['snippet']}\" for h in hits)[:max_ctx_chars]\n",
        "    sys_msg = (\n",
        "        \"Top: Dominance donut between Microcystis / Cylindrospermopsis.\\n\\n\"\n",
        "        \"Middle: Basic water quality â€” pH, nitrate, nitrite, turbidity.\\n\\n\"\n",
        "        \"Bottom: General water status â€” clear traffic-light indicator + explanation.\\n\"\n",
        "    )\n",
        "    ans = None\n",
        "    if USE_OPENAI and openai_client:\n",
        "        try:\n",
        "            resp = openai_client.chat.completions.create(\n",
        "                model=GEN_MODEL,\n",
        "                messages=[\n",
        "                    {\"role\":\"system\",\"content\":sys_msg},\n",
        "                    {\"role\":\"user\",\"content\":f\"×§×•× ×˜×§×¡×˜:\\n{ctx}\\n\\n×©××œ×”: {question}\\n\\n×”×—×–×¨ 1â€“2 ××©×¤×˜×™× ×‘×œ×‘×“.\"}\n",
        "                ],\n",
        "                temperature=0.1, max_tokens=180\n",
        "            )\n",
        "            ans = (resp.choices[0].message.content or \"\").strip()\n",
        "        except Exception as e:\n",
        "            print(\"âŒ OpenAI short-answer error:\", e)\n",
        "            ans = None\n",
        "    if not ans or len(ans) < 40 or SAFE_PHRASE in ans:\n",
        "        ans = _short_best_effort_from_hits(hits, max_chars=400)\n",
        "    return _trim_hebrew(ans, max_chars=400, max_words=80, max_sentences=2)\n",
        "\n",
        "def rag_answer_big(question: str, k: int = 100, max_ctx_chars: int = 6000,\n",
        "                   max_sentences: int = 15, max_words: int = 600, max_chars: int = 6000) -> str:\n",
        "    hits = rag_search(question, k=k)\n",
        "    if not hits:\n",
        "        return SAFE_FALLBACK\n",
        "    ctx = \"\\n\\n\".join(f\"[{h['title']}] {h['snippet']}\" for h in hits)[:max_ctx_chars]\n",
        "    sys_msg = (\n",
        "        \"×¢× ×” ×‘×× ×’×œ×™×ª ×¤×©×•×˜×”, ×‘×™×Ÿ 10 ×œÖ¾15 ××©×¤×˜×™× ×¨×¦×•×¤×™×, ×œ××” ×”××¦×‘ ×˜×•×‘ ××• ×œ× ×˜×•×‘. \"\n",
        "        \"×”×©×ª××© ×‘×”×¡×‘×¨×™× ××¤×•×¨×˜×™×. ×”×ª×‘×¡×¡ ×’× ×¢×œ ×”×§×•× ×˜×§×¡×˜ ×•×’× ×¢×œ ×™×“×¢ ×›×œ×œ×™. \"\n",
        "        \"××œ ×ª×¦×˜×˜ ×•××œ ×ª×©×ª××© ×‘×¨×©×™××•×ª.\"\n",
        "    )\n",
        "    ans = None\n",
        "    if USE_OPENAI and openai_client:\n",
        "        try:\n",
        "            resp = openai_client.chat.completions.create(\n",
        "                model=GEN_MODEL,\n",
        "                messages=[{\"role\":\"system\",\"content\":sys_msg},\n",
        "                          {\"role\":\"user\",\"content\":f\"×§×•× ×˜×§×¡×˜:\\n{ctx}\\n\\n×©××œ×”: {question}\"}],\n",
        "                temperature=0.3, max_tokens=1200\n",
        "            )\n",
        "            ans = (resp.choices[0].message.content or \"\").strip()\n",
        "        except Exception as e:\n",
        "            print(\"âŒ OpenAI error:\", e); ans = None\n",
        "    if not ans:\n",
        "        ans = \"×œ× × ×™×ª×Ÿ ×œ×”×¤×™×§ ×ª×©×•×‘×” ××¨×•×›×” â€“ ×™×™×ª×›×Ÿ ×©×”××•×“×œ ×œ× ×¢×‘×“.\"\n",
        "    return _trim_hebrew(ans, max_chars=max_chars, max_words=max_words, max_sentences=max_sentences)\n",
        "\n",
        "# ============ Data sources for Dashboard ============\n",
        "SHEET_SPECIES = \"https://docs.google.com/spreadsheets/d/1v5o3MTe0rAEdZNDl6RPZpk4sPsARV5vgL_IxSdpbSbQ/export?format=csv&gid=1894462874\"\n",
        "SHEET_ENV     = \"https://docs.google.com/spreadsheets/d/1yhk-ybout_eG0cdQsZERacRyk97bfj1gahZsXNA_lwA/export?format=csv&gid=1765612268\"\n",
        "\n",
        "MICRO_COL = \"cyanophyta_chroococales_2-microcystis_flos-aquae\"\n",
        "CYL_COL   = \"cyanophyta_hormogonales_2-cylindrospermopsis_raciborskyi\"\n",
        "SPECIES = [\n",
        "    {\"name\":\"Microcystis\",        \"short\":\"Micro\", \"col\": MICRO_COL},\n",
        "    {\"name\":\"Cylindrospermopsis\", \"short\":\"Cyl\",   \"col\": CYL_COL},\n",
        "]\n",
        "\n",
        "DONUT_HEIGHT      = 260\n",
        "DONUT_TITLE_SIZE  = 14\n",
        "DONUT_TEXT_SIZE   = 12\n",
        "TRAFFIC_HEIGHT    = 160\n",
        "\n",
        "SHOW_DEBUG = False\n",
        "ENV_OVERRIDE = {\n",
        "    \"pH\":       \"avg_ph\",\n",
        "    \"Nitrate\":  \"avg_nitrate\",\n",
        "    \"Nitrite\":  \"avg_nitrit\",\n",
        "    \"Turbidity\":\"avg_turbidity\",\n",
        "}\n",
        "\n",
        "def _load_csv(url):\n",
        "    df = pd.read_csv(url, dtype=str, encoding=\"utf-8\", on_bad_lines=\"skip\")\n",
        "    date_candidates = [c for c in df.columns if c and c.strip().lower() in (\"date\",\"sample_date\",\"×ª××¨×™×š\")]\n",
        "    date_col = date_candidates[0] if date_candidates else \"date\"\n",
        "    if date_col not in df.columns:\n",
        "        df[date_col] = pd.Series(pd.date_range(end=pd.Timestamp.today(), periods=len(df))).dt.normalize()\n",
        "    dt = pd.to_datetime(df[date_col], errors=\"coerce\", utc=True)\n",
        "    df[date_col] = pd.Series(dt).dt.tz_localize(None)\n",
        "    if date_col != \"date\":\n",
        "        df = df.rename(columns={date_col:\"date\"})\n",
        "    num_re = r'^[\\s\\+\\-]?\\d+([.,]\\d+)?([eE][\\+\\-]?\\d+)?$'\n",
        "    for c in df.columns:\n",
        "        if c == \"date\": continue\n",
        "        s = df[c].astype(str).str.strip()\n",
        "        if s.str.match(num_re).fillna(False).mean() >= 0.2:\n",
        "            df[c] = pd.to_numeric(s.str.replace(\",\", \".\", regex=False), errors=\"coerce\")\n",
        "        else:\n",
        "            df[c] = s\n",
        "    df = df.sort_values(\"date\", na_position=\"first\").reset_index(drop=True)\n",
        "    return df\n",
        "\n",
        "@lru_cache(maxsize=1)\n",
        "def load_species(): return _load_csv(SHEET_SPECIES)\n",
        "@lru_cache(maxsize=1)\n",
        "def load_env():     return _load_csv(SHEET_ENV)\n",
        "\n",
        "def nearest_row(df, date_str):\n",
        "    s = df[\"date\"].dropna()\n",
        "    latest_idx = s.idxmax()\n",
        "    if not date_str or str(date_str).strip().lower() == \"latest\":\n",
        "        return df.loc[latest_idx]\n",
        "    target = pd.to_datetime(date_str, errors=\"coerce\", utc=True)\n",
        "    if pd.isna(target): return df.loc[latest_idx]\n",
        "    target = pd.Timestamp(target).tz_localize(None)\n",
        "    if target <= s.min(): return df.loc[s.idxmin()]\n",
        "    if target >= s.max(): return df.loc[latest_idx]\n",
        "    return df.loc[(s - target).abs().idxmin()]\n",
        "\n",
        "def donut(labels, values, title):\n",
        "    vals = [0 if (v is None or (isinstance(v,float) and np.isnan(v)) or float(v) < 0) else float(v) for v in values]\n",
        "    if sum(vals) == 0: vals = [0.5, 0.5]\n",
        "    fig = go.Figure(go.Pie(\n",
        "        labels=labels, values=vals, hole=0.55, sort=False,\n",
        "        textinfo=\"percent\", textposition=\"inside\", textfont=dict(size=DONUT_TEXT_SIZE),\n",
        "        hovertemplate=\"%{label}<br>Value: %{value:.6g}<br>%{percent}<extra></extra>\",\n",
        "        direction=\"clockwise\", showlegend=False\n",
        "    ))\n",
        "    fig.update_layout(title=dict(text=title, font=dict(size=DONUT_TITLE_SIZE)),\n",
        "                      margin=dict(l=6,r=6,t=32,b=8), height=DONUT_HEIGHT,\n",
        "                      paper_bgcolor=\"white\", plot_bgcolor=\"white\")\n",
        "    return fig\n",
        "\n",
        "def _norm(s: str) -> str:\n",
        "    # Normalize header tokens: trim, lowercase, convert sub/sup digits, unify dashes, drop slashes, keep only [a-z0-9 + Hebrew range]\n",
        "    s = str(s).strip().lower()\n",
        "    s = s.translate(str.maketrans(\"â‚€â‚â‚‚â‚ƒâ‚„â‚…â‚†â‚‡â‚ˆâ‚‰\", \"0123456789\"))\n",
        "    s = s.translate(str.maketrans(\"â°Â¹Â²Â³â´âµâ¶â·â¸â¹\", \"0123456789\"))\n",
        "    s = s.replace(\"â»\",\"-\").replace(\"âˆ’\",\"-\").replace(\"â€“\",\"-\").replace(\"/\", \"\")\n",
        "    s = re.sub(r'[^a-z0-9×-×ª]+', '', s)\n",
        "    return s\n",
        "\n",
        "ENV_TOKENS = {\n",
        "    \"pH\":       [\"ph\",\"p.h\",\"×—×•××¦×™×•×ª\",\"×—×•××¦×”\"],\n",
        "    \"nitrate\":  [\"nitrate\",\"nitrates\",\"no3\",\"no3-\",\"avgno3\",\"avgnitrate\",\"× ×™×˜×¨××˜\",\"× ×™×˜×¨××˜×™×\",\"×—× ×§×”\"],\n",
        "    \"nitrite\":  [\"nitrite\",\"nitrites\",\"no2\",\"no2-\",\"avgno2\",\"avgnitrite\",\"avg_nitrite\",\"avg_nitrit\",\"avg_no2\",\"no2mgl\",\"no2mg_l\",\"× ×™×˜×¨×™×˜\",\"× ×™×˜×¨×™×˜×™×\"],\n",
        "    \"turbidity\":[\"turbidity\",\"ntu\",\"avgturbidity\",\"×¢×›×™×¨×•×ª\"]\n",
        "}\n",
        "\n",
        "def pick_env_cols(row_env):\n",
        "    cols = {}\n",
        "    norm_map = {h: _norm(h) for h in list(row_env.index)}\n",
        "    for key, toks in ENV_TOKENS.items():\n",
        "        chosen = None\n",
        "        for h, hn in norm_map.items():\n",
        "            if any(tok in hn for tok in toks):\n",
        "                chosen = h; break\n",
        "        cols[key] = chosen\n",
        "    ov = ENV_OVERRIDE\n",
        "    if ov.get(\"pH\") and ov[\"pH\"] in row_env.index: cols[\"pH\"] = ov[\"pH\"]\n",
        "    if ov.get(\"Nitrate\") and ov[\"Nitrate\"] in row_env.index: cols[\"nitrate\"] = ov[\"Nitrate\"]\n",
        "    if ov.get(\"Nitrite\") and ov[\"Nitrite\"] in row_env.index: cols[\"nitrite\"] = ov[\"Nitrite\"]\n",
        "    if ov.get(\"Turbidity\") and ov[\"Turbidity\"] in row_env.index: cols[\"turbidity\"] = ov[\"Turbidity\"]\n",
        "    return cols\n",
        "\n",
        "def classify_env(value, metric):\n",
        "    if value is None or pd.isna(value): return (\"No data\", \"â€”\")\n",
        "    v = float(value)\n",
        "    if metric == \"pH\":\n",
        "        if v < 6.0 or v > 9.0:               return (\"Bad\", \"pH outside 6.0â€“9.0\")\n",
        "        if 6.0 <= v < 6.5 or 8.5 <= v <= 9.0: return (\"Warning\", \"pH in 6.0â€“6.5 or 8.5â€“9.0\")\n",
        "        return (\"Good\", \"pH 6.5â€“8.5\")\n",
        "    if metric == \"nitrate\":\n",
        "        if v > 50:                            return (\"Bad\", \"NOâ‚ƒâ» > 50 mg/L\")\n",
        "        if 25 <= v <= 50:                     return (\"Warning\", \"NOâ‚ƒâ» 25â€“50 mg/L\")\n",
        "        return (\"Good\", \"NOâ‚ƒâ» < 25 mg/L\")\n",
        "    if metric == \"nitrite\":\n",
        "        if v > 0.2:                           return (\"Bad\", \"NOâ‚‚â» > 0.2 mg/L\")\n",
        "        if 0.1 <= v <= 0.2:                   return (\"Warning\", \"NOâ‚‚â» 0.1â€“0.2 mg/L\")\n",
        "        return (\"Good\", \"NOâ‚‚â» < 0.1 mg/L\")\n",
        "    if metric == \"turbidity\":\n",
        "        if v > 5:                             return (\"Bad\", \"NTU > 5\")\n",
        "        if 1 <= v <= 5:                       return (\"Warning\", \"NTU 1â€“5\")\n",
        "        return (\"Good\", \"NTU < 1\")\n",
        "    return (\"No data\", \"â€”\")\n",
        "\n",
        "def env_bullet_charts(row_env, date_text):\n",
        "    cols = pick_env_cols(row_env)\n",
        "    def _get_val(key):\n",
        "        col = cols.get(key)\n",
        "        if col is None: return np.nan\n",
        "        try: return float(row_env.get(col, np.nan))\n",
        "        except Exception: return np.nan\n",
        "\n",
        "    pH_val  = _get_val(\"pH\")\n",
        "    no3_val = _get_val(\"nitrate\")\n",
        "    no2_val = _get_val(\"nitrite\")\n",
        "    ntu_val = _get_val(\"turbidity\")\n",
        "\n",
        "    numstyle = {\"valueformat\":\".3g\", \"font\":{\"size\":26}}\n",
        "\n",
        "    fig_top = make_subplots(\n",
        "        rows=1, cols=2, specs=[[{\"type\":\"indicator\"},{\"type\":\"indicator\"}]],\n",
        "        vertical_spacing=0.0, horizontal_spacing=0.18\n",
        "    )\n",
        "    fig_top.add_trace(go.Indicator(\n",
        "        mode=\"number+gauge\", number=numstyle,\n",
        "        value=0 if pd.isna(pH_val) else float(pH_val),\n",
        "        gauge={\n",
        "            \"shape\":\"bullet\",\"axis\":{\"range\":[0,14]},\n",
        "            \"steps\":[\n",
        "                {\"range\":[0,6.0],\"color\":\"#f4c7c3\"},\n",
        "                {\"range\":[6.0,6.5],\"color\":\"#fff2cc\"},\n",
        "                {\"range\":[6.5,8.5],\"color\":\"#b7e1cd\"},\n",
        "                {\"range\":[8.5,9.0],\"color\":\"#fff2cc\"},\n",
        "                {\"range\":[9.0,14],\"color\":\"#f4c7c3\"}\n",
        "            ],\n",
        "            \"threshold\":{\"line\":{\"color\":\"black\",\"width\":3}, \"value\":0 if pd.isna(pH_val) else float(pH_val)}\n",
        "        }),\n",
        "        row=1, col=1\n",
        "    )\n",
        "    fig_top.add_trace(go.Indicator(\n",
        "        mode=\"number+gauge\", number=numstyle,\n",
        "        value=0 if pd.isna(no3_val) else float(no3_val),\n",
        "        gauge={\n",
        "            \"shape\":\"bullet\",\"axis\":{\"range\":[0,60]},\n",
        "            \"steps\":[\n",
        "                {\"range\":[0,25],\"color\":\"#b7e1cd\"},\n",
        "                {\"range\":[25,50],\"color\":\"#fff2cc\"},\n",
        "                {\"range\":[50,60],\"color\":\"#f4c7c3\"}\n",
        "            ],\n",
        "            \"threshold\":{\"line\":{\"color\":\"black\",\"width\":3}, \"value\":0 if pd.isna(no3_val) else float(no3_val)}\n",
        "        }),\n",
        "        row=1, col=2\n",
        "    )\n",
        "    fig_top.update_layout(height=260, margin=dict(l=70, r=160, t=20, b=10))\n",
        "\n",
        "    fig_bottom = make_subplots(\n",
        "        rows=1, cols=2, specs=[[{\"type\":\"indicator\"},{\"type\":\"indicator\"}]],\n",
        "        vertical_spacing=0.0, horizontal_spacing=0.18\n",
        "    )\n",
        "    fig_bottom.add_trace(go.Indicator(\n",
        "        mode=\"number+gauge\", number=numstyle,\n",
        "        value=0 if pd.isna(no2_val) else float(no2_val),\n",
        "        gauge={\n",
        "            \"shape\":\"bullet\",\"axis\":{\"range\":[0,0.3]},\n",
        "            \"steps\":[\n",
        "                {\"range\":[0,0.1],\"color\":\"#b7e1cd\"},\n",
        "                {\"range\":[0.1,0.2],\"color\":\"#fff2cc\"},\n",
        "                {\"range\":[0.2,0.3],\"color\":\"#f4c7c3\"}\n",
        "            ],\n",
        "            \"threshold\":{\"line\":{\"color\":\"black\",\"width\":3}, \"value\":0 if pd.isna(no2_val) else float(no2_val)}\n",
        "        }),\n",
        "        row=1, col=1\n",
        "    )\n",
        "    fig_bottom.add_trace(go.Indicator(\n",
        "        mode=\"number+gauge\", number=numstyle,\n",
        "        value=0 if pd.isna(ntu_val) else float(ntu_val),\n",
        "        gauge={\n",
        "            \"shape\":\"bullet\",\"axis\":{\"range\":[0,6]},\n",
        "            \"steps\":[\n",
        "                {\"range\":[0,1],\"color\":\"#b7e1cd\"},\n",
        "                {\"range\":[1,5],\"color\":\"#fff2cc\"},\n",
        "                {\"range\":[5,6],\"color\":\"#f4c7c3\"}\n",
        "            ],\n",
        "            \"threshold\":{\"line\":{\"color\":\"black\",\"width\":3}, \"value\":0 if pd.isna(ntu_val) else float(ntu_val)}\n",
        "        }),\n",
        "        row=1, col=2\n",
        "    )\n",
        "    fig_bottom.update_layout(height=260, margin=dict(l=70, r=160, t=20, b=10))\n",
        "\n",
        "    classes = {\n",
        "        \"pH\":       classify_env(pH_val,\"pH\"),\n",
        "        \"Nitrate\":  classify_env(no3_val,\"nitrate\"),\n",
        "        \"Nitrite\":  classify_env(no2_val,\"nitrite\"),\n",
        "        \"Turbidity\":classify_env(ntu_val,\"turbidity\"),\n",
        "    }\n",
        "    values = {\"pH\":pH_val, \"Nitrate\":no3_val, \"Nitrite\":no2_val, \"Turbidity\":ntu_val}\n",
        "    mapped_cols = {\n",
        "        \"pH\": cols.get(\"pH\"),\n",
        "        \"Nitrate\": cols.get(\"nitrate\"),\n",
        "        \"Nitrite\": cols.get(\"nitrite\"),\n",
        "        \"Turbidity\": cols.get(\"turbidity\")\n",
        "    }\n",
        "    return fig_top, fig_bottom, classes, values, mapped_cols\n",
        "\n",
        "def overall_from_classes(classes):\n",
        "    order = {\"Good\":0, \"Warning\":1, \"Bad\":2, \"No data\":1}\n",
        "    worst = max(order.get(v[0],1) for v in classes.values())\n",
        "    return worst, {0:\"Good\",1:\"Warning\",2:\"Bad\"}[worst]\n",
        "\n",
        "def traffic_light_fig(severity_code):\n",
        "    # Build a simple 3-light indicator: Good / Warning / Poor (English labels)\n",
        "    sizes = [60, 60, 60]; sizes[severity_code] = 90\n",
        "    borders = [1, 1, 1]; borders[severity_code] = 5\n",
        "    colors_on  = [\"#2e7d32\",\"#f9a825\",\"#c62828\"]\n",
        "    colors_dim = [\"#c8e6c9\",\"#fff9c4\",\"#ffcdd2\"]\n",
        "    cols = [colors_dim[0], colors_dim[1], colors_dim[2]]\n",
        "    cols[severity_code] = colors_on[severity_code]\n",
        "    fig = go.Figure()\n",
        "    fig.add_trace(go.Scatter(\n",
        "        x=[0,1,2], y=[0,0,0], mode=\"markers+text\",\n",
        "        marker=dict(size=sizes, color=cols, line=dict(width=borders, color=\"#333\")),\n",
        "        text=[\"Good\",\"Warning\",\"Poor\"], textposition=\"bottom center\", textfont=dict(size=14)\n",
        "    ))\n",
        "    fig.add_annotation(x=severity_code, y=-0.5, text=\"â–¼\", showarrow=False, font=dict(size=28))\n",
        "    fig.update_xaxes(visible=False); fig.update_yaxes(visible=False, range=[-1,1])\n",
        "    fig.update_layout(height=TRAFFIC_HEIGHT, margin=dict(l=20,r=20,t=10,b=10), paper_bgcolor=\"white\")\n",
        "    return fig\n",
        "\n",
        "def risk_explanation(classes, values):\n",
        "    lines = []\n",
        "    pv = values[\"pH\"]; st_pH = classes[\"pH\"][0]\n",
        "    if not pd.isna(pv):\n",
        "        if st_pH == \"Warning\":\n",
        "            if float(pv) >= 8.5:\n",
        "                lines.append(f\"- *pH {float(pv):.2f}*: Above **9.0** would be non-compliant (Bad).\")\n",
        "            elif float(pv) <= 6.5:\n",
        "                lines.append(f\"- *pH {float(pv):.2f}*: Below **6.0** would be non-compliant (Bad).\")\n",
        "        else:\n",
        "            lines.append(\"- *pH*: Non-compliant if < **6.0** or > **9.0**.\")\n",
        "    if not pd.isna(values[\"Nitrate\"]):\n",
        "        lines.append(\"- *NOâ‚ƒâ» (nitrate)*: Non-compliant if > **50 mg/L**.\")\n",
        "    if not pd.isna(values[\"Nitrite\"]):\n",
        "        lines.append(\"- *NOâ‚‚â» (nitrite)*: Non-compliant if > **0.2 mg/L**.\")\n",
        "    if not pd.isna(values[\"Turbidity\"]):\n",
        "        lines.append(\"- *Turbidity (NTU)*: Non-compliant if > **5**.\")\n",
        "    if not lines:\n",
        "        lines.append(\"No water-quality data found to explain.\")\n",
        "    return \"### When might it become *non-compliant*?\\n\" + \"\\n\".join(lines)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# ============ Telegram (optional) ============\n",
        "\n",
        "#i cant enter tokken\n",
        "BOT_TOKEN =\n",
        "CHANNEL   = \"@planktometer\"\n",
        "\n",
        "def post_to_telegram(text: str):\n",
        "    # Define BASE_TELE here\n",
        "    BASE_TELE = f\"https://api.telegram.org/bot{BOT_TOKEN}\"\n",
        "    if not (BOT_TOKEN and CHANNEL):\n",
        "        return \"âš ï¸ ×—×¡×¨ BOT_TOKEN ××• CHANNEL ×‘×¡×‘×™×‘×ª ×”×”×¨×¦×”.\"\n",
        "    try:\n",
        "        r = requests.get(f\"{BASE_TELE}/sendMessage\", params={\"chat_id\": CHANNEL, \"text\": text})\n",
        "        return f\"×¡×˜×˜×•×¡ ×˜×œ×’×¨×: {r.status_code}\"\n",
        "    except Exception as e:\n",
        "        return f\"×©×’×™××ª ×˜×œ×’×¨×: {e}\"\n",
        "\n",
        "# ============ UI ============\n",
        "CSS = \"\"\"\n",
        ".gradio-container { direction: ltr; }\n",
        "#wrap { width: min(980px, 100%); margin-left:auto; }\n",
        "#wrap .gr-markdown, #wrap .gr-html, #wrap .gr-textbox label { text-align:left; }\n",
        "#qbox textarea { direction: ltr; text-align: left; height: 70px; }\n",
        "#fixed-bar{\n",
        "  position: fixed; right: 16px; bottom: 16px; z-index: 9999;\n",
        "  display: flex; gap: 10px; padding: 10px 12px;\n",
        "  background: #111827cc; backdrop-filter: blur(6px);\n",
        "  border-radius: 14px; box-shadow: 0 10px 25px rgba(0,0,0,.25);\n",
        "}\n",
        "#fixed-bar a{\n",
        "  text-decoration: none; padding: 10px 14px; border-radius: 10px;\n",
        "  font-weight: 600; font-family: system-ui, Arial; font-size: 14px;\n",
        "}\n",
        "#fixed-bar a.btn        { background: #e5e7eb; color:#111827; }\n",
        "#fixed-bar a.btn.primary{ background: #e5e7eb; color:#111827; }\n",
        "\n",
        "#qbox textarea,\n",
        "#summary_box textarea,\n",
        "#explanation_box textarea {\n",
        "  direction: ltr;\n",
        "  text-align: left;\n",
        "}\n",
        "\n",
        "/* Left alignment for Markdown/HTML */\n",
        "#wrap .gr-markdown,\n",
        "#wrap .gr-html,\n",
        "#wrap .gr-textbox label {\n",
        "  text-align: left;\n",
        "  direction: ltr;\n",
        "}\n",
        "#wrap .gr-markdown h1,\n",
        "#wrap .gr-markdown h2,\n",
        "#wrap .gr-markdown h3,\n",
        "#wrap .gr-markdown p,\n",
        "#wrap .gr-markdown li {\n",
        "  text-align: left;\n",
        "}\n",
        "#intro_md,\n",
        "#intro_md * {\n",
        "  direction: ltr;\n",
        "  text-align: left;\n",
        "}\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "df_s = load_species()\n",
        "df_e = load_env()\n",
        "\n",
        "def dashboard_run(date_str):\n",
        "    # Donut\n",
        "    row_s = nearest_row(df_s, date_str)\n",
        "    d_s = pd.to_datetime(row_s[\"date\"]).strftime(\"%Y-%m-%d\")\n",
        "    names, shorts, vals = [], [], []\n",
        "    for sp in SPECIES:\n",
        "        names.append(sp[\"name\"]); shorts.append(sp[\"short\"])\n",
        "        vals.append(row_s[sp[\"col\"]] if sp[\"col\"] in df_s.columns else np.nan)\n",
        "    safe = [0 if pd.isna(v) or v is None else float(v) for v in vals]\n",
        "    total = sum(safe)\n",
        "    if total > 0:\n",
        "        perc = [100*v/total for v in safe]; win = int(np.argmax(perc))\n",
        "        dom_txt = f\"*Dominant:* {names[win]} ({shorts[win]}) â€” {perc[win]:.1f}%\"\n",
        "    else:\n",
        "        dom_txt = \"*Dominant:* â€” (no measurable values)\"\n",
        "    donut_fig = donut([f\"{names[i]} ({shorts[i]})\" for i in range(len(names))], safe, f\"Dominance on {d_s}\")\n",
        "    info = f\"*Nearest date (Plankton):* {d_s}  \\n{dom_txt}\"\n",
        "\n",
        "    # Env\n",
        "    row_e = nearest_row(df_e, date_str)\n",
        "    d_e = pd.to_datetime(row_e[\"date\"]).strftime(\"%Y-%m-%d\")\n",
        "    env_fig_top, env_fig_bottom, env_classes, env_values, env_cols = env_bullet_charts(row_e, d_e)\n",
        "    top_left_title  = f\"*pH* â€” {d_e}\"\n",
        "    top_right_title = f\"**Nitrate (mg/L)** â€” {d_e}\"\n",
        "    bot_left_title  = f\"*Nitrite (mg/L)* â€” {d_e}\"\n",
        "    bot_right_title = f\"**Turbidity (NTU)** â€” {d_e}\"\n",
        "    env_lines = [f\"- *{k}*: {v[0]} â€” {v[1]}\" for k, v in env_classes.items()]\n",
        "    env_text = \"*Water quality status (nearest date):* \" + d_e + \"\\n\" + \"\\n\".join(env_lines)\n",
        "    if SHOW_DEBUG:\n",
        "        matched = \" | \".join([f\"{k} â†’ {('â€”' if env_cols[k] is None else env_cols[k])}\" for k in [\"pH\",\"Nitrate\",\"Nitrite\",\"Turbidity\"]])\n",
        "        env_text += f\"\\n\\n_Detected columns:_ {matched}\"\n",
        "\n",
        "    # Overall\n",
        "    sev_code, sev_label = overall_from_classes(env_classes)\n",
        "    overall_fig = traffic_light_fig(sev_code)\n",
        "    label_en = {\"Good\":\"Water quality is good âœ…\", \"Warning\":\"Warning âš ï¸\", \"Bad\":\"Poor water quality ğŸ›‘\"}[sev_label]\n",
        "    overall_md = f\"## {label_en}  \\n*Based on pH / NOâ‚ƒâ» / NOâ‚‚â» / NTU on the same date*\"\n",
        "\n",
        "    # Risk explanation\n",
        "    risk_text = risk_explanation(env_classes, env_values)\n",
        "\n",
        "    # Build summary string for Telegram (and/or for RAG explain)\n",
        "    summary = f\"\"\"===== PlanktoMeter Summary =====\n",
        "Plankton date: {d_s}\n",
        "- {names[0]} ({shorts[0]}): {safe[0]:.3g}\n",
        "- {names[1]} ({shorts[1]}): {safe[1]:.3g}\n",
        "{dom_txt}\n",
        "\n",
        "Water quality date: {d_e}\n",
        "- pH: {env_classes['pH'][0]} ({env_classes['pH'][1]}); value: {env_values['pH']}\n",
        "- Nitrate (mg/L): {env_classes['Nitrate'][0]} ({env_classes['Nitrate'][1]}); value: {env_values['Nitrate']}\n",
        "- Nitrite (mg/L): {env_classes['Nitrite'][0]} ({env_classes['Nitrite'][1]}); value: {env_values['Nitrite']}\n",
        "- Turbidity (NTU): {env_classes['Turbidity'][0]} ({env_classes['Turbidity'][1]}); value: {env_values['Turbidity']}\n",
        "\n",
        "Overall status: {label_en}\n",
        "*Based on pH / NOâ‚ƒâ» / NOâ‚‚â» / NTU on the same date*\"\"\"\n",
        "\n",
        "    # Short model-based explanation\n",
        "    y = rag_explain_bad(summary, k=3)  # Assign the result to y\n",
        "    BOT_TOKEN = \"8211215726:AAHC7zNzdnbDETrlzdUGHPBP_6schsX3hqE\"\n",
        "    CHANNEL   = \"@planktometer\"\n",
        "    base = f\"https://api.telegram.org/bot{BOT_TOKEN}\"\n",
        "    r2 = requests.get(f\"{base}/sendMessage\", params={\"chat_id\": CHANNEL, \"text\": y})\n",
        "    r2 = requests.get(f\"{base}/sendMessage\", params={\"chat_id\": CHANNEL, \"text\": summary})\n",
        "\n",
        "    # Removed Telegram posting from this function as it should be triggered by a button\n",
        "    return (info, donut_fig,\n",
        "            top_left_title, top_right_title, env_fig_top,\n",
        "            bot_left_title, bot_right_title, env_fig_bottom,\n",
        "            env_text, overall_fig, overall_md, risk_text,\n",
        "            summary, y)\n",
        "\n",
        "\n",
        "def ui_answer(q: str, mode: str) -> str:\n",
        "    q = (q or \"\").strip()\n",
        "    if not q:\n",
        "        return \"<div dir='ltr' style='text-align:left'>Please type a questionâ€¦</div>\"\n",
        "    if mode == \"Short answer\":\n",
        "        txt = rag_answer_tiny(q)\n",
        "    elif mode == \"Detailed answer\":\n",
        "        txt = rag_answer_big(q)\n",
        "    elif mode == \"Answer with sources\":\n",
        "        hits = rag_search(q)\n",
        "        txt = rag_answer_tiny(q) + \"\\n\\nSources:\\n\" + \"\\n\".join([f\"- {h['title']}\" for h in hits])\n",
        "    else:\n",
        "        txt = rag_answer_tiny(q)\n",
        "    return f\"<div dir='ltr' style='text-align:left; white-space:pre-wrap'>{txt}</div>\"\n",
        "\n",
        "\n",
        "TELEGRAM_URL = \"https://t.me/planktometer\"\n",
        "CONTACT_URL  = \"https://www.canva.com/design/DAGzQUG4HeU/zavwMeCZQbHVe4T9YhfGeA/view?utm_content=DAGzQUG4HeU&utm_campaign=designshare&utm_medium=link2&utm_source=uniquelinks&utlId=hca940222a4\"\n",
        "\n",
        "\n",
        "with gr.Blocks(title=\"PlanktoMeter â€” Unified\", css=CSS, theme=\"soft\") as demo:\n",
        "    with gr.Tab(\"Dashboard\"):\n",
        "        gr.Markdown(\n",
        "            \"## PlanktoMeter\\n\"\n",
        "            \"*Top:* Dominance donut between Microcystis/Cylindrospermopsis.\\n\\n\"\n",
        "            \"*Middle:* Basic water quality â€” pH, nitrate, nitrite, turbidity.\\n\\n\"\n",
        "            \"*Bottom:* General water status â€” clear traffic-light indicator + explanation.\\n\",\n",
        "            elem_id=\"intro_md\"\n",
        "        )\n",
        "        with gr.Row():\n",
        "            with gr.Column(scale=1, min_width=230):\n",
        "                date_tb = gr.Textbox(value=\"Latest\", label=\"Date (YYYY-MM-DD)\", placeholder=\"YYYY-MM-DD or Latest\")\n",
        "                run_btn = gr.Button(\"Show\")\n",
        "                info_md = gr.Markdown()\n",
        "            with gr.Column(scale=2, min_width=420):\n",
        "                donut_plot = gr.Plot(show_label=False)\n",
        "\n",
        "        gr.Markdown(\"### Basic water quality\")\n",
        "        with gr.Row():\n",
        "            with gr.Column(scale=3, min_width=660):\n",
        "                with gr.Row():\n",
        "                    env_title_top_left  = gr.Markdown()\n",
        "                    env_title_top_right = gr.Markdown()\n",
        "                env_plot_top = gr.Plot(show_label=False)\n",
        "                with gr.Row():\n",
        "                    env_title_bot_left  = gr.Markdown()\n",
        "                    env_title_bot_right = gr.Markdown()\n",
        "                env_plot_bottom = gr.Plot(show_label=False)\n",
        "            with gr.Column(scale=2, min_width=320):\n",
        "                env_md = gr.Markdown()\n",
        "\n",
        "        gr.Markdown(\"### General water status\")\n",
        "        with gr.Row():\n",
        "            with gr.Column(scale=3, min_width=660):\n",
        "                overall_plot = gr.Plot(show_label=False)\n",
        "            with gr.Column(scale=2, min_width=320):\n",
        "                overall_text = gr.Markdown()\n",
        "        risk_md = gr.Markdown()\n",
        "\n",
        "        # Summary & send boxes\n",
        "        with gr.Row():\n",
        "            summary_box     = gr.Textbox(label=\"Summary\", lines=8, elem_id=\"summary_box\")\n",
        "            explanation_box = gr.Textbox(label=\"Short explanation (RAG)\", lines=8, elem_id=\"explanation_box\")\n",
        "        send_status = gr.Markdown()\n",
        "\n",
        "        # The function that runs the dashboard and returns all outputs\n",
        "        def _run_and_fill(date_str):\n",
        "            return dashboard_run(date_str)\n",
        "\n",
        "        run_btn.click(\n",
        "            _run_and_fill, inputs=[date_tb],\n",
        "            outputs=[\n",
        "                info_md, donut_plot,\n",
        "                env_title_top_left, env_title_top_right, env_plot_top,\n",
        "                env_title_bot_left, env_title_bot_right, env_plot_bottom,\n",
        "                env_md, overall_plot, overall_text, risk_md,\n",
        "                summary_box, explanation_box\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        def _send_to_tele(summary_text, explanation_text):\n",
        "            text = (summary_text or \"\").strip()\n",
        "            if explanation_text:\n",
        "                text += \"\\n\\n\" + explanation_text\n",
        "            return post_to_telegram(text)\n",
        "\n",
        "    with gr.Tab(\"RAG Q&A\"):\n",
        "        with gr.Column(elem_id=\"wrap\"):\n",
        "            gr.Markdown(\"## PlanktoMeter â€“ RAG Q&A\")\n",
        "            with gr.Row():\n",
        "                q = gr.Textbox(label=\"Question\", placeholder=\"Type your questionâ€¦\", lines=3, elem_id=\"qbox\")\n",
        "            with gr.Row():\n",
        "                answer_mode = gr.Radio(\n",
        "                    [\"Short answer\", \"Detailed answer\", \"Answer with sources\"],\n",
        "                    label=\"Choose answer type\", value=\"Short answer\"\n",
        "                )\n",
        "            with gr.Row():\n",
        "                ask_btn = gr.Button(\"Ask\")\n",
        "                clear_btn = gr.Button(\"Clear\")\n",
        "            out_html = gr.HTML(label=\"Answer\")\n",
        "            gr.Examples(\n",
        "                examples=[\n",
        "                    \"What is the risk of cyanobacterial bloom at the sampling stations?\",\n",
        "                    \"Summarize the findings about phytoplankton.\",\n",
        "                    \"What is mentioned about zooplankton in the relevant sections?\"\n",
        "                ],\n",
        "                inputs=q\n",
        "            )\n",
        "\n",
        "            # If your ui_answer still expects Hebrew modes, normalize inside it as shown earlier.\n",
        "            ask_btn.click(fn=ui_answer, inputs=[q, answer_mode], outputs=out_html)\n",
        "            clear_btn.click(lambda: (\"\", \"Short answer\", \"\"), inputs=None, outputs=[q, answer_mode, out_html])\n",
        "\n",
        "    # --- Third tab: Peaks ---\n",
        "    with gr.Tab(\"Peaks\"):\n",
        "        gr.Markdown(\"### Turbidity & Cyanobacteria â€” Top 5 Peaks (auto-display)\")\n",
        "        gr.Markdown(\n",
        "            \"- Slider picks **which peak** (by turbidity) to show. 1 = highest\\n\"\n",
        "            \"- Lines use **connectgaps=True** so they wonâ€™t break when data is missing.\\n\"\n",
        "            \"- Second chart adds a **Water Quality Index (0â€“100)** vs **plankton amount**.\"\n",
        "        )\n",
        "        pk_rank_in   = gr.Slider(1, PK_TOP_K, value=1, step=1, label=\"Select Peak Rank (1 = highest)\")\n",
        "        pk_plot_out1 = gr.Plot(label=\"Turbidity vs Plankton â€” Â±1 month\")\n",
        "        pk_plot_out2 = gr.Plot(label=\"Water Quality vs Plankton â€” Â±1 month\")\n",
        "\n",
        "        # Initial load when the page opens\n",
        "        demo.load(lambda: pk_build_plots_for_rank(1), inputs=None, outputs=[pk_plot_out1, pk_plot_out2])\n",
        "        # Update when the slider changes\n",
        "        pk_rank_in.change(pk_build_plots_for_rank, inputs=pk_rank_in, outputs=[pk_plot_out1, pk_plot_out2])\n",
        "\n",
        "    # Anything outside Tabs should come after the tabs group\n",
        "    gr.HTML(f\"\"\"\n",
        "<div id=\"fixed-bar\">\n",
        "  <a class=\"btn\" href=\"{TELEGRAM_URL}\" target=\"_blank\" rel=\"noopener\">Telegram feed</a>\n",
        "  <a class=\"btn primary\" href=\"{CONTACT_URL}\" target=\"_blank\" rel=\"noopener\">Contact</a>\n",
        "</div>\n",
        "\"\"\")\n",
        "\n",
        "\n",
        "\n",
        "demo.launch(share=True, debug=False)"
      ],
      "metadata": {
        "id": "Adk9MqfsECmq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 702
        },
        "outputId": "1cd42199-a0b6-4da3-a563-1198dffeb103"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ§¹ Cleaned extras (if existed).\n",
            "âœ”ï¸ Base installed. Run the next cell to restart runtime.\n",
            "âœ”ï¸ Extra deps installed\n",
            "ğŸ“¦ PdfReader provider: pypdf\n",
            "âœ”ï¸ Pinned google-genai + websockets 14.1\n",
            "âœ… OpenAI\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://4a254fec2edc3e2a3f.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://4a254fec2edc3e2a3f.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    }
  ]
}